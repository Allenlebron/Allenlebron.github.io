---
layout:     post
title:      Hadoop全家桶之实战篇一
subtitle:   
date:       2019-03-14
author:     zwilpan
header-img: img/bigdatalearning.jpg
catalog: true
tags:
    - BigData
---

从这篇开始我们就从最简单的官方案例来学习hadoop，关于运行环境的基本配置就不再详细总结了。这个谷歌百度上有大量的教程可以参考，在装好linux配置好后，需要安装jdk和hadoop安装包。hadoop版本>=2.7：要求Java 7(openjdk/oracle)以上。通过java -version和hadoop version命令来查看是否安装成功。成功后我们就可以一起来尝试运行hadoo的官方案例。由于篇幅的问题，我将分为三篇文章从单机到集群配置来运行官网的hadoop案例，今天我们先来从最简单的单机也就是本地模式来运行第一个hadoop案例（hadoop-2.7.2版本）

## Hadoop的运行模式

+ 本地模式(Local Mode)
不需要启用单独进程，直接可以运行，测试使用

+ 伪分布式模式(Pseudo-Distributed Mode)
等同于只有一个节点的完全分布式

+ 完全分布式模式(Fully-Distributed Mode)
多个节点一起运行

#### 本地运行官方grep案例 
1.在安装好的hadoop-2.7.2目录下面创建一个input文件夹

![avatar](/img/grep01.png)
2.将hadoop-2.7.2的xml文件复制到input文件夹

![avatar](/img/grep02.png)
3.运行share目录下的MapReduce程序（查找以dfs开头的单词）
![avatar](/img/grep03.png)

4.查看输出结果(最后看到dfsadmin就说明运行成功了)
![avatar](/img/grep04.jpg)  


#### 本地运行官方wordcount案例
1.在hadoop-2.7.2目录下面创建一个wcinput文件夹  
2.在wcinput文件下创建一个wc.input文件  
3.编辑wc.input文件  
![avatar](/img/wordcount03.jpg)

4.回到hadoop目录/opt/moudle/hadoop-2.7.2执行程序  
![avatar](/img/wordcount04.jpg)

5.查看结果：  
![avatar](/img/wordcount05.jpg)

### 伪分布式运行Hadoop案例

#### 启动HDFS并运行MapReduce程序  

+ 1.配置集群  
a.配置：hadoop-env.sh  
export JAVA_HOME=/opt/moudle/jdk1.8.0_171  

b.配置core-site.xml  

    <!-- 指定HDFS中NameNode的地址 -->  
    <property>  
    <name>fs.defaultFS</name>  
    <value>hdfs://zwilpan001:9000</value>  
    </property>

    <!-- 指定hadoop运行时产生文件的存储目录 -->
    <property>
    <name>hadoop.tmp.dir</name>
    <value>/opt/module/hadoop-2.7.2/data/tmp</value>
    </property>

2.启动集群  
a.格式化namenode（初次格式化就可以）  
在hadoop目录下执行：bin/hdfs namenode -format  

b.启动namenode  
在hadoop目录下执行：sbin/hadoop-daemon.sh start namenode  

c.启动datanode  
在hadoop目录下执行：sbin/hadoop-daemon.sh start datanode

3.查看集群  
a.查看是否启动成功  
执行命令：jps  

b.web端查看HDFS文件系统  
http://zwilpan001:50070/dfshealth.html#tab-overview

4.操作集群  
a.在hdfs文件系统上创建一个input文件夹  
b.将测试内容上传到文件系统上  
c.查看文件上传是否正确  
d.运行mapreduce程序  
e.查看输出结果  
f.将测试文件内容下载到本地  
g.删除输出结果  

####  YARN上运行MapReduce程序  
1.配置集群  
a.配置：yarn-env.sh  
export JAVA_HOME=/opt/moudle/jdk1.8.0_171  

b.配置yarn-site.xml  
<!-- reducer获取数据的方式 -->
    <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
    </property>

<!-- 指定YARN的ResourceManager的地址 -->
    <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>zwilpan001</value>
    </property>

c.配置：mapred-env.sh  
export JAVA_HOME=/opt/module/jdk1.8.0_144  
d.修改mapred-site.xml.template  
重新命名为mapred-site.xml，改成yarn模式运行

    <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
    </property>
			
2.启动集群  
a.启动前保证namenode和datanode已经启动  

b.启动resourcemanager  
在hadoop目录下执行：sbin/yarn-daemon.sh start resourcemanager  

c.启动nodemanager 
在hadoop目录下执行：sbin/yarn-daemon.sh start nodemanager
			
3.查看集群  
a.查看yarn的浏览器页面  
http://zwilpan001:8088/cluster
		
4.操作集群   
a.执行mapReduce程序  
在hadoop目录下执行：  
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar   wordcount /user/zwilpan001/input /user/zwilpan001/output  

b.查看运行结果  
在hadoop目录下执行：  
bin/hdfs dfs -cat /user/zwilpan001/output/*

5.配置历史服务器  

6.日志的聚集（应用运行完成以后，将日志信息上传到HDFS系统上）
