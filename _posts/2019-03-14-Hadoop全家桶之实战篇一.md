---
layout:     post
title:      Hadoop全家桶之实战篇一
subtitle:   
date:       2019-03-14
author:     zwilpan
header-img: img/bigdatalearning.jpg
catalog: true
tags:
    - BigData
---

从这篇开始我们就从最简单的官方案例来学习hadoop，关于运行环境的基本配置就不再详细总结了。这个谷歌百度上有大量的教程可以参考，在装好linux配置好后，需要安装jdk和hadoop安装包。hadoop版本>=2.7：要求Java 7(openjdk/oracle)以上。通过java -version和hadoop version命令来查看是否安装成功。成功后我们就可以一起来尝试运行hadoo的官方案例。由于篇幅的问题，我将分为三篇文章从单机到集群配置来运行官网的hadoop案例，今天我们先来从最简单的单机也就是本地模式来运行第一个hadoop案例（hadoop-2.7.2版本）

## Hadoop的运行模式

+ 本地模式(Local Mode)
不需要启用单独进程，直接可以运行，测试使用

+ 伪分布式模式(Pseudo-Distributed Mode)
等同于只有一个节点的完全分布式

+ 完全分布式模式(Fully-Distributed Mode)
多个节点一起运行

### 本地运行官方grep案例 
1.在安装好的hadoop-2.7.2目录下面创建一个input文件夹

![avatar](/img/grep01.png)
2.将hadoop-2.7.2的xml文件复制到input文件夹

![avatar](/img/grep02.png)
3.运行share目录下的MapReduce程序（查找以dfs开头的单词）
![avatar](/img/grep03.png)

4.查看输出结果(最后看到dfsadmin就说明运行成功了)
![avatar](/img/grep04.png)  


### 本地运行官方wordcount案例
1.在hadoop-2.7.2目录下面创建一个wcinput文件夹  
![avatar](/img/wordcount01.jpg)

2.在wcinput文件下创建一个wc.input文件  
![avatar](/img/wordcount02.jpg)

3.编辑wc.input文件  
![avatar](/img/wordcount03.jpg)

4.回到hadoop目录/opt/moudle/hadoop-2.7.2执行程序  
![avatar](/img/wordcount04.jpg)

6.查看结果：  
![avatar](/img/wordcount05.jpg)

